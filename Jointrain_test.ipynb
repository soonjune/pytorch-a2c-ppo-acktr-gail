{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from a2c_ppo_acktr import algo, utils\n",
    "from a2c_ppo_acktr.arguments import get_args\n",
    "from a2c_ppo_acktr.envs import make_vec_envs\n",
    "from a2c_ppo_acktr.model import Policy, Bandit_Policy\n",
    "from a2c_ppo_acktr.storage import RolloutStorage, SkipReplayBuffer\n",
    "from evaluation import evaluate\n",
    "from sb3_contrib import QRDQN, TQC, TRPO\n",
    "from stable_baselines3 import A2C, DDPG, DQN, PPO, SAC, TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGOS = {\n",
    "    \"a2c\": A2C,\n",
    "    \"ddpg\": DDPG,\n",
    "    \"dqn\": DQN,\n",
    "    \"ppo\": PPO,\n",
    "    \"sac\": SAC,\n",
    "    \"td3\": TD3,\n",
    "    # SB3 Contrib,\n",
    "    \"qrdqn\": QRDQN,\n",
    "    \"tqc\": TQC,\n",
    "    \"trpo\": TRPO,\n",
    "}\n",
    "\n",
    "algo = \"dqn\"\n",
    "env_id = \"BreakoutNoFrameskip-v4\"\n",
    "seed = 1\n",
    "num_processes = 1\n",
    "device = \"cpu\"\n",
    "eval_log_dir = \"./\"\n",
    "\n",
    "model_path = os.path.join('./rl-trained-agents/' , algo, env_id+\"_1\", env_id+\".zip\") \n",
    "bandit_path = os.path.join('./experiments/' , env_id, \"bdqn\", \"20220106T224832.135078\", \"trained_models\" , env_id+\".pt\")\n",
    "env = make_vec_envs(env_id, seed, num_processes, 0.99, eval_log_dir, device, False)\n",
    "model = ALGOS[algo].load(model_path, env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.replay_buffer.add\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_net = torch.load(bandit_path, map_location=torch.device('cpu'))[1]\n",
    "theta = torch.load(bandit_path, map_location=torch.device('cpu'))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "deterministic = False # Deterministic by default except for atari games\n",
    "state = None\n",
    "episode_reward = 0.0\n",
    "episode_rewards, episode_lengths = [], []\n",
    "ep_len = 0\n",
    "eval_episode_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(eval_episode_rewards) < 1:\n",
    "    action, state = model.predict(obs.numpy(), state=state, deterministic=deterministic)\n",
    "    obs, reward, done, infos = env.step(torch.tensor([action]))\n",
    "    \n",
    "    episode_reward += reward[0]\n",
    "    ep_len += 1\n",
    "\n",
    "    for info in infos:\n",
    "        if 'episode' in info.keys():\n",
    "            eval_episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluation using 1 episodes: mean reward 375.00000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Evaluation using {} episodes: mean reward {:.5f}\\n\".format(\n",
    "        len(eval_episode_rewards), np.mean(eval_episode_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_len \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQN' object has no attribute 'recurrent_hidden_state_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77077/1551132525.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m eval_recurrent_hidden_states = torch.zeros(\n\u001b[0;32m----> 4\u001b[0;31m     num_processes, model.recurrent_hidden_state_size, device=device)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0meval_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DQN' object has no attribute 'recurrent_hidden_state_size'"
     ]
    }
   ],
   "source": [
    "eval_episode_rewards = []\n",
    "obs = env.reset()\n",
    "eval_recurrent_hidden_states = torch.zeros(\n",
    "    num_processes, model.recurrent_hidden_state_size, device=device)\n",
    "eval_masks = torch.zeros(num_processes, 1, device=device)\n",
    "i = 0\n",
    "skip = 0\n",
    "rep_count = 0\n",
    "rep_l = []\n",
    "old_action = 99\n",
    "while len(eval_episode_rewards) < 1:\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "    if skip == 0:\n",
    "        with torch.no_grad():\n",
    "            _, action, _, eval_recurrent_hidden_states = model.act(\n",
    "                obs,\n",
    "                eval_recurrent_hidden_states,\n",
    "                eval_masks,\n",
    "                deterministic=True)\n",
    "        old_action = action\n",
    "        skip = 3\n",
    "    else:\n",
    "        action = old_action\n",
    "        skip -= 1\n",
    "\n",
    "\n",
    "    #print(i, action)\n",
    "    # Obser reward and next obs\n",
    "    obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "    eval_masks = torch.tensor(\n",
    "        [[0.0] if done_ else [1.0] for done_ in done],\n",
    "        dtype=torch.float32,\n",
    "        device=device)\n",
    "    #img_save_dir = img_dir + '{}.png'.format(i)\n",
    "    #plt.imsave( img_save_dir , obs[0][0])\n",
    "    \n",
    "    for info in infos:\n",
    "        if 'episode' in info.keys():\n",
    "            eval_episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MsPacmanNoFrameskip-v4\"\n",
    "path = f\"./experiments/{env_name}/a2c/a2c_2/trained_models/{env_name}.pt\"\n",
    "seed = 1\n",
    "num_processes = 1\n",
    "eval_log_dir = './'\n",
    "device = \"cpu\"\n",
    "img_dir = './render_img/'\n",
    "actor_critic = torch.load(path, map_location=torch.device('cpu'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = make_vec_envs(env_name, seed, num_processes, 0.99, eval_log_dir, device, False)\n",
    "eval_episode_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = envs.reset()\n",
    "eval_recurrent_hidden_states = torch.zeros(\n",
    "    num_processes, actor_critic.recurrent_hidden_state_size, device=device)\n",
    "eval_masks = torch.zeros(num_processes, 1, device=device)\n",
    "i = 0\n",
    "skip = 0\n",
    "rep_count = 0\n",
    "rep_l = []\n",
    "old_action = 99\n",
    "while len(eval_episode_rewards) < 1:\n",
    "    i+=1\n",
    "\n",
    "    '''with torch.no_grad():\n",
    "        _, action, _, eval_recurrent_hidden_states = actor_critic.act(\n",
    "            obs,\n",
    "            eval_recurrent_hidden_states,\n",
    "            eval_masks,\n",
    "            deterministic=True)\n",
    "    if old_action == action:\n",
    "        rep_count +=1\n",
    "    else:\n",
    "        if rep_count >0:\n",
    "            rep_l.append(rep_count)\n",
    "        rep_count = 0\n",
    "    \n",
    "    old_action = action'''\n",
    "\n",
    "\n",
    "    \n",
    "    if skip == 0:\n",
    "        with torch.no_grad():\n",
    "            _, action, _, eval_recurrent_hidden_states = actor_critic.act(\n",
    "                obs,\n",
    "                eval_recurrent_hidden_states,\n",
    "                eval_masks,\n",
    "                deterministic=True)\n",
    "        old_action = action\n",
    "        skip = 3\n",
    "    else:\n",
    "        action = old_action\n",
    "        skip -= 1\n",
    "\n",
    "\n",
    "    #print(i, action)\n",
    "    # Obser reward and next obs\n",
    "    obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "    eval_masks = torch.tensor(\n",
    "        [[0.0] if done_ else [1.0] for done_ in done],\n",
    "        dtype=torch.float32,\n",
    "        device=device)\n",
    "    #img_save_dir = img_dir + '{}.png'.format(i)\n",
    "    #plt.imsave( img_save_dir , obs[0][0])\n",
    "    \n",
    "    for info in infos:\n",
    "        if 'episode' in info.keys():\n",
    "            eval_episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluation using 1 episodes: mean reward 770.00000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Evaluation using {} episodes: mean reward {:.5f}\\n\".format(\n",
    "        len(eval_episode_rewards), np.mean(eval_episode_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 0 artists>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w = Counter(rep_l)\n",
    "plt.bar(w.keys(), w.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e7b5364a21053ac17f8a7b362bd086a5b8c0d62d27224356fb7b7059aee21a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('atari': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
